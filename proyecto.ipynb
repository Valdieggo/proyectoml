{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo con datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECCION DATOS DE ENTRENAMIENTO Y TEST , 2023 SE USARAN PARA TEST\n",
    "data_train = pd.read_csv('atp_matches_2000.csv')\n",
    "data_test=pd.read_csv('atp_matches_2023.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the data from 2001 to 2022\n",
    "for i in range(1, 22):\n",
    "    data_train = pd.concat([data_train, pd.read_csv('atp_matches_20' + str(i).zfill(2) + '.csv')])\n",
    "data_train.index = range(0,len(data_train)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player1_id', 'player1_ht', 'player1_age', 'player2_id', 'player2_ht',\n",
      "       'player2_age', 'player1_rank_points', 'player2_rank_points',\n",
      "       'player_id_win', 'surface_encoded', 'player1_hand_encoded',\n",
      "       'player2_hand_encoded', 'tourney_level_encoded',\n",
      "       'player1_entry_encoded', 'player2_entry_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21675/2256230725.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected_train['player_id_win'] = data_selected_train['winner_id']\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las columnas deseadas\n",
    "selected_columns = ['tourney_id', 'surface', 'tourney_level', 'winner_id', 'winner_entry', 'winner_hand', 'winner_ht', 'winner_age', 'loser_id', 'loser_entry', 'loser_hand', 'loser_ht', 'loser_age', 'winner_rank_points', 'loser_rank_points']\n",
    "\n",
    "# Se crea un dataframe con las columnas seleccionadas\n",
    "data_selected_train = data_train[selected_columns]\n",
    "\n",
    "# Crear una nueva columna llamadaplayer_id_win\n",
    "data_selected_train['player_id_win'] = data_selected_train['winner_id']\n",
    "\n",
    "\n",
    "data_selected_train = data_selected_train.rename(columns={\n",
    "    'winner_id': 'player1_id',\n",
    "    'winner_entry': 'player1_entry',\n",
    "    'winner_hand': 'player1_hand',\n",
    "    'winner_ht': 'player1_ht',\n",
    "    'winner_age': 'player1_age',\n",
    "    'winner_rank_points': 'player1_rank_points',\n",
    "    'loser_id': 'player2_id',\n",
    "    'loser_entry': 'player2_entry',\n",
    "    'loser_hand': 'player2_hand',\n",
    "    'loser_ht': 'player2_ht',\n",
    "    'loser_age': 'player2_age',\n",
    "    'loser_rank_points': 'player2_rank_points'\n",
    "})\n",
    "# Mapeo para 'surface'\n",
    "surface_mapping = {'Clay': 0, 'Grass': 1, 'Hard': 2, 'Carpet': 3} \n",
    "data_selected_train['surface_encoded'] = data_selected_train['surface'].map(surface_mapping)\n",
    "\n",
    "# Mapeo para 'winner_hand'\n",
    "hand_mapping = {'R': 0, 'L': 1, 'U': 2}  # Puedes ajustar esto según tus datos\n",
    "data_selected_train['player1_hand_encoded'] = data_selected_train['player1_hand'].map(hand_mapping)\n",
    "data_selected_train['player2_hand_encoded'] = data_selected_train['player2_hand'].map(hand_mapping)\n",
    "data_selected_train = data_selected_train.drop(['surface', 'player1_hand','player2_hand'], axis=1)\n",
    "\n",
    "# Reemplazar el guion '-' con una cadena vacía ''\n",
    "data_selected_train['tourney_id'] = data_selected_train['tourney_id'].str.replace('-', '')\n",
    "\n",
    "\n",
    "tourney_level_mapping = {'G': 0, 'M': 1, 'A': 2, 'C': 3, 'S': 4, 'F': 5, 'D': 6}  # Puedes ajustar esto según tus datos\n",
    "data_selected_train['tourney_level_encoded'] = data_selected_train['tourney_level'].map(tourney_level_mapping)\n",
    "\n",
    "# Eliminar la columna original 'tourney_level'\n",
    "data_selected_train = data_selected_train.drop(['tourney_level'], axis=1)\n",
    "\n",
    "winner_entry_mapping = {'WC': 1, 'Q': 2, 'LL': 3, 'PR': 4} \n",
    "data_selected_train['player1_entry_encoded'] = data_selected_train['player1_entry'].map(winner_entry_mapping)\n",
    "data_selected_train['player2_entry_encoded'] = data_selected_train['player2_entry'].map(winner_entry_mapping)\n",
    "\n",
    "# Eliminar la columna original 'player1_entry' y 'player2_entry'\n",
    "data_selected_train = data_selected_train.drop(['player1_entry', 'player2_entry'], axis=1)\n",
    "# Reemplazar NaN con 0 en 'player1_entry_encoded' y 'player2_entry_encoded'\n",
    "data_selected_train['player1_entry_encoded'].fillna(0, inplace=True)\n",
    "data_selected_train['player2_entry_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'tourney_id'\n",
    "data_selected_train = data_selected_train.drop(['tourney_id'], axis=1)\n",
    "data_selected_train = data_selected_train.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "#print(data_selected.head())\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "print(data_selected_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player1_id', 'player1_ht', 'player1_age', 'player2_id', 'player2_ht',\n",
      "       'player2_age', 'player1_rank_points', 'player2_rank_points',\n",
      "       'player_id_win', 'surface_encoded', 'player1_hand_encoded',\n",
      "       'player2_hand_encoded', 'tourney_level_encoded',\n",
      "       'player1_entry_encoded', 'player2_entry_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21675/294209450.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected_test['player_id_win'] = data_selected_test['winner_id']\n"
     ]
    }
   ],
   "source": [
    "# Se crea un dataframe con las columnas seleccionadas\n",
    "data_selected_test = data_test[selected_columns]\n",
    "\n",
    "# Crear una nueva columna llamada player_id_win\n",
    "data_selected_test['player_id_win'] = data_selected_test['winner_id']\n",
    "\n",
    "data_selected_test = data_selected_test.rename(columns={\n",
    "    'winner_id': 'player1_id',\n",
    "    'winner_entry': 'player1_entry',\n",
    "    'winner_hand': 'player1_hand',\n",
    "    'winner_ht': 'player1_ht',\n",
    "    'winner_age': 'player1_age',\n",
    "    'winner_rank_points': 'player1_rank_points',\n",
    "    'loser_id': 'player2_id',\n",
    "    'loser_entry': 'player2_entry',\n",
    "    'loser_hand': 'player2_hand',\n",
    "    'loser_ht': 'player2_ht',\n",
    "    'loser_age': 'player2_age',\n",
    "    'loser_rank_points': 'player2_rank_points'\n",
    "})\n",
    "# Mapeo para 'surface'\n",
    "surface_mapping = {'Clay': 0, 'Grass': 1, 'Hard': 2, 'Carpet': 3} \n",
    "data_selected_test['surface_encoded'] = data_selected_test['surface'].map(surface_mapping)\n",
    "\n",
    "# Mapeo para 'winner_hand'\n",
    "hand_mapping = {'R': 0, 'L': 1, 'U': 2}  # Puedes ajustar esto según tus datos\n",
    "data_selected_test['player1_hand_encoded'] = data_selected_test['player1_hand'].map(hand_mapping)\n",
    "data_selected_test['player2_hand_encoded'] = data_selected_test['player2_hand'].map(hand_mapping)\n",
    "data_selected_test = data_selected_test.drop(['surface', 'player1_hand','player2_hand'], axis=1)\n",
    "\n",
    "# Reemplazar el guion '-' con una cadena vacía ''\n",
    "data_selected_test['tourney_id'] = data_selected_test['tourney_id'].str.replace('-', '')\n",
    "\n",
    "tourney_level_mapping = {'G': 0, 'M': 1, 'A': 2, 'C': 3, 'S': 4, 'F': 5, 'D': 6}  # Puedes ajustar esto según tus datos\n",
    "data_selected_test['tourney_level_encoded'] = data_selected_test['tourney_level'].map(tourney_level_mapping)\n",
    "\n",
    "# Eliminar la columna original 'tourney_level'\n",
    "data_selected_test = data_selected_test.drop(['tourney_level'], axis=1)\n",
    "\n",
    "winner_entry_mapping = {'WC': 1, 'Q': 2, 'LL': 3, 'PR': 4} \n",
    "data_selected_test['player1_entry_encoded'] = data_selected_test['player1_entry'].map(winner_entry_mapping)\n",
    "data_selected_test['player2_entry_encoded'] = data_selected_test['player2_entry'].map(winner_entry_mapping)\n",
    "\n",
    "# Eliminar la columna original 'player1_entry' y 'player2_entry'\n",
    "data_selected_test = data_selected_test.drop(['player1_entry', 'player2_entry'], axis=1)\n",
    "# Reemplazar NaN con 0 en 'player1_entry_encoded' y 'player2_entry_encoded'\n",
    "data_selected_test['player1_entry_encoded'].fillna(0, inplace=True)\n",
    "data_selected_test['player2_entry_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'tourney_id'\n",
    "data_selected_test = data_selected_test.drop(['tourney_id'], axis=1)\n",
    "data_selected_test = data_selected_test.dropna()\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "print(data_selected_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_selected_train['player_id_win']\n",
    "x_train = data_selected_train.drop(['player_id_win'], axis=1)\n",
    "\n",
    "y_test= data_selected_test['player_id_win']\n",
    "x_test = data_selected_test.drop(['player_id_win'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo con datos set2 para redes sequenciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el set de datos siempre gana el player uno, por lo que se podria esperar que la red aprenda este patron, se haran redes de clasificacion binaria, siendo 1 para cuando gana el player 1 y o para cunado gana el player 2 , acontinuacion se presenta el cambio de un porsentaje del set donde se dan vuelta los player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia exacta del DataFrame data_selected y llamarla dataset2\n",
    "dataset2_train = data_selected_train.copy()\n",
    "# Este dataset cumpple la funcion de entrenar un modelo binario de capas densas donde se usa 1 para indicar que gana el player 1 y 0 para indicar que gana el player 2\n",
    "dataset2_train['win'] = 1\n",
    "\n",
    "\n",
    "dataset2_test = data_selected_test.copy()\n",
    "dataset2_test['win'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EN EL SET DE DATOS SIEMPRE GANA EL PLAYER UNO \n",
    "\n",
    "# Establecer una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tamano_subset = int(0.55 * len(dataset2_train))\n",
    "\n",
    "# Seleccionar al azar un subconjunto de filas para intercambiar las instancias\n",
    "indices_a_cambiar = np.random.choice(dataset2_train.index, size=tamano_subset, replace=False)  # ajusta el tamaño según sea necesario\n",
    "\n",
    "# Copiar las características y etiquetas de Player 1 en dataset2\n",
    "features_player1 = dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]]\n",
    "labels_player1 = 1 - dataset2_train.loc[indices_a_cambiar, 'win']  # Invertir las etiquetas para representar victorias de Player 2\n",
    "\n",
    "# Copiar las características y etiquetas de Player 2 en dataset2\n",
    "features_player2 = dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]]\n",
    "labels_player2 = dataset2_train.loc[indices_a_cambiar, 'win']\n",
    "\n",
    "# Actualizar las instancias de Player 1 en dataset2 con las de Player 2\n",
    "dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]] = features_player2.values\n",
    "dataset2_train.loc[indices_a_cambiar, 'win'] = labels_player2.values  # Invertir las etiquetas en 'win'\n",
    "\n",
    "# Actualizar las instancias de Player 2 en dataset2 con las de Player 1\n",
    "dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]] = features_player1.values\n",
    "dataset2_train.loc[indices_a_cambiar, 'win'] = labels_player1.values\n",
    "\n",
    "# Verificar los primeros registros del DataFrame actualizado (dataset2)\n",
    "#print(dataset2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el mismo trabajo para el dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tamano_subset = int(0.55 * len(dataset2_test))\n",
    "\n",
    "# Seleccionar al azar un subconjunto de filas para intercambiar las instancias\n",
    "indices_a_cambiar = np.random.choice(dataset2_test.index, size=tamano_subset, replace=False)  # ajusta el tamaño según sea necesario\n",
    "\n",
    "# Copiar las características y etiquetas de Player 1 en dataset2\n",
    "features_player1 = dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]]\n",
    "labels_player1 = 1 - dataset2_test.loc[indices_a_cambiar, 'win']  # Invertir las etiquetas para representar victorias de Player 2\n",
    "\n",
    "# Copiar las características y etiquetas de Player 2 en dataset2\n",
    "features_player2 = dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]]\n",
    "labels_player2 = dataset2_test.loc[indices_a_cambiar, 'win']\n",
    "\n",
    "# Actualizar las instancias de Player 1 en dataset2 con las de Player 2\n",
    "dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]] = features_player2.values\n",
    "dataset2_test.loc[indices_a_cambiar, 'win'] = labels_player2.values  # Invertir las etiquetas en 'win'\n",
    "\n",
    "# Actualizar las instancias de Player 2 en dataset2 con las de Player 1\n",
    "dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]] = features_player1.values\n",
    "dataset2_test.loc[indices_a_cambiar, 'win'] = labels_player1.values\n",
    "\n",
    "# Verificar los primeros registros del DataFrame actualizado (dataset2_test)\n",
    "#print(dataset2_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62327\n",
      "34279\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "print(len(dataset2_train))\n",
    "print(len(dataset2_train[dataset2_train['win'] == 0]))\n",
    "\n",
    "y_dataset2_train = dataset2_train['win']\n",
    "x_dataset2_train = dataset2_train.drop(['player_id_win','win'], axis=1)\n",
    "#y_dataset2_ht= tf.keras.utils.to_categorical(dataset2_train['win'])\n",
    "\n",
    "y_dataset2_test = dataset2_test['win']\n",
    "x_dataset2_test = dataset2_test.drop(['player_id_win','win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset2_test))\n",
    "print(len(dataset2_test[dataset2_test['win'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2702169625246548"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model5 = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "model5.fit(x_dataset2_train, y_dataset2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.653353057199211"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.score(x_dataset2_test,y_dataset2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#joblib.dump(model5, 'models/random_forest_model5.plk', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo secuencial con capas densas y modo de activacion relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "print(YOUR_INPUT_DIM)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(30, activation=\"relu\", input_dim=YOUR_INPUT_DIM))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(50, activation=\"relu\"))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(20, activation=\"relu\"))\n",
    "model1.add(Dense(units=1, activation='sigmoid'))  \n",
    "model1.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "974/974 [==============================] - 2s 1ms/step - loss: 364.1646 - accuracy: 0.5225 - val_loss: 0.6890 - val_accuracy: 0.5498\n",
      "Epoch 2/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 1.5119 - accuracy: 0.5468 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 3/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.8961 - accuracy: 0.5492 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 4/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.8952 - accuracy: 0.5494 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 5/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.8247 - accuracy: 0.5499 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 6/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.8350 - accuracy: 0.5497 - val_loss: 0.6883 - val_accuracy: 0.5498\n",
      "Epoch 7/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.7070 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 8/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.7109 - accuracy: 0.5499 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 9/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6970 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 10/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6970 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 11/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 12/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6962 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 13/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.7001 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 14/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.7068 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 15/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 16/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 17/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 18/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 19/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 20/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n"
     ]
    }
   ],
   "source": [
    "model1a=model1.fit(x_dataset2_train, y_dataset2_train, epochs=20, batch_size=64, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model1.epoch, model1.history['accuracy'], label='train')\n",
    "plt.plot(model1.epoch, model1.history['val_accuracy'], label='val')\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epoch\")\n",
    "plt.title(\"Entrenamiento\")\n",
    "plt.legend()\n",
    "#plt.savefig('entrenamientomodel1_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.save('models/keras_model1_relu62.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=model1.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "#print(\"Loss:\", results[0])\n",
    "#print(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo secuencial de capas densas con activacion LeakyRELU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(70, activation=LeakyReLU(alpha=0.07), input_dim=YOUR_INPUT_DIM))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(25, activation=LeakyReLU(alpha=0.07)))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(30, activation=LeakyReLU(alpha=0.06)))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))  \n",
    "model2.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=model2.fit(x_dataset2_train, y_dataset2_train, epochs=50, batch_size=64, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.save('models/keras_model2_leaky63.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model2.epoch, model2.history['accuracy'], label='train')\n",
    "plt.plot(model2.epoch, model2.history['val_accuracy'], label='val')\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epoch\")\n",
    "plt.title(\"Entrenamiento\")\n",
    "plt.legend()\n",
    "#plt.savefig('entrenamientomodel2_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model2, to_file='modelo1.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=model2.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "#print(\"Loss:\", results[0])\n",
    "p#rint(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrenamiento de un tercer modelo secuancial con capas densas y activacion relu y LeakyReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(30, activation=\"relu\", input_dim=YOUR_INPUT_DIM))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(70, activation=LeakyReLU(alpha=0.06)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(50, activation=LeakyReLU(alpha=0.06)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(25, activation=\"relu\"))\n",
    "model3.add(Dense(units=1, activation='sigmoid'))  \n",
    "model3.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=model3.fit(x_dataset2_train, y_dataset2_train, epochs=55, batch_size=68, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.save('models/keras_model3_64_relu_leaky.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model3.epoch, model3.history['accuracy'], label='train')\n",
    "plt.plot(model3.epoch, model3.history['val_accuracy'], label='val')\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epoch\")\n",
    "plt.title(\"Entrenamiento\")\n",
    "plt.legend()\n",
    "#plt.savefig('entrenamientomodel3_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=model3.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "#print(\"Loss:\", results[0])\n",
    "#print(\"Accuracy:\", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
